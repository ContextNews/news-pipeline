name: Run Pipeline

on:
  schedule:
    - cron: "0 6,18 * * *"
  workflow_dispatch:
    inputs:
      # Ingest inputs
      ingest-lookback-hours:
        description: 'Number of hours to look back for articles'
        type: number
        default: 12
      ingest-sources:
        description: 'Sources'
        type: string
        default: 'all'
      # Shared date input for embed, entities, and resolve-entities
      published-date:
        description: 'Process articles published on this date (UTC, YYYY-MM-DD) - used for embed, entities, resolve-entities'
        type: string
        default: ''
      # Shared overwrite input for all stages after ingest
      overwrite:
        description: 'Re-process articles/clusters/stories even if already processed'
        type: boolean
        default: true
      # Embed inputs
      embed-model:
        description: 'Sentence-transformers model name'
        type: string
        default: 'all-MiniLM-L6-v2'
      embed-batch-size:
        description: 'Batch size for encoding'
        type: number
        default: 32
      embed-word-limit:
        description: 'Embedded words limit'
        type: number
        default: 300
      embed-no-title:
        description: 'Exclude title from embedding'
        type: boolean
        default: false
      embed-no-summary:
        description: 'Exclude summary from embedding'
        type: boolean
        default: false
      embed-no-text:
        description: 'Exclude text from embedding'
        type: boolean
        default: false
      # Extract entities inputs
      entities-model:
        description: 'spaCy model to use'
        type: string
        default: 'en_core_web_trf'
      entities-batch-size:
        description: 'Batch size for spaCy NER'
        type: number
        default: 32
      entities-word-limit:
        description: 'Entity extraction word limit'
        type: number
        default: 300
      # Cluster inputs
      cluster-ingested-date:
        description: 'UTC date to load from RDS (YYYY-MM-DD)'
        type: string
        default: ''
      cluster-embedding-model:
        description: 'Embedding model to use'
        type: string
        default: 'all-MiniLM-L6-v2'
      cluster-min-cluster-size:
        description: 'Minimum cluster size'
        type: number
        default: 2
      cluster-min-samples:
        description: 'Minimum samples (leave empty for default)'
        type: number
        default: 0
      # Cronkite (story generation & classification) inputs
      cronkite-model:
        description: 'OpenAI model for story generation and classification'
        type: string
        default: 'gpt-4o-mini'
      stories-cluster-period:
        description: 'UTC cluster period to process (YYYY-MM-DD)'
        type: string
        default: ''

permissions:
  id-token: write
  contents: read

jobs:
  ingest:
    uses: ./.github/workflows/ingest_articles.yaml
    secrets: inherit
    with:
      lookback-hours: ${{ fromJSON(inputs.ingest-lookback-hours || '12') }}
      sources: ${{ inputs.ingest-sources || 'all' }}
      load-s3: true
      load-rds: true

  # Embed and extract-entities run in parallel after ingest
  embed:
    needs: ingest
    uses: ./.github/workflows/compute_embeddings.yaml
    secrets: inherit
    with:
      published-date: ${{ inputs.published-date || '' }}
      model: ${{ inputs.embed-model || 'all-MiniLM-L6-v2' }}
      batch-size: ${{ fromJSON(inputs.embed-batch-size || '32') }}
      word-limit: ${{ fromJSON(inputs.embed-word-limit || '300') }}
      no-title: ${{ inputs.embed-no-title == true }}
      no-summary: ${{ inputs.embed-no-summary == true }}
      no-text: ${{ inputs.embed-no-text == true }}
      overwrite: ${{ inputs.overwrite == true }}
      load-s3: true
      load-rds: true

  extract-entities:
    needs: ingest
    uses: ./.github/workflows/extract_entities.yaml
    secrets: inherit
    with:
      published-date: ${{ inputs.published-date || '' }}
      model: ${{ inputs.entities-model || 'en_core_web_trf' }}
      batch-size: ${{ fromJSON(inputs.entities-batch-size || '32') }}
      word-limit: ${{ fromJSON(inputs.entities-word-limit || '300') }}
      overwrite: ${{ inputs.overwrite == true }}
      load-s3: true
      load-rds: true

  # Resolve entities after entities are extracted
  resolve-entities:
    needs: extract-entities
    uses: ./.github/workflows/resolve_entities.yaml
    secrets: inherit
    with:
      published-date: ${{ inputs.published-date || '' }}
      overwrite: ${{ inputs.overwrite == true }}
      load-s3: true
      load-rds: true

  # Cluster only needs embeddings
  cluster:
    needs: embed
    uses: ./.github/workflows/cluster_articles.yaml
    secrets: inherit
    with:
      ingested-date: ${{ inputs.cluster-ingested-date || '' }}
      embedding-model: ${{ inputs.cluster-embedding-model || 'all-MiniLM-L6-v2' }}
      min-cluster-size: ${{ fromJSON(inputs.cluster-min-cluster-size || '2') }}
      min-samples: ${{ fromJSON(inputs.cluster-min-samples || '0') }}
      load-s3: true
      load-rds: true
      overwrite-clusters: ${{ inputs.overwrite == true }}

  # Generate and classify stories after clustering and entity resolution
  generate-stories:
    needs: [cluster, resolve-entities]
    uses: ./.github/workflows/generate_stories.yaml
    secrets: inherit
    with:
      cluster-period: ${{ inputs.stories-cluster-period || '' }}
      model: ${{ inputs.cronkite-model || 'gpt-4o-mini' }}
      load-s3: true
      load-rds: true
      overwrite: ${{ inputs.overwrite == true }}
