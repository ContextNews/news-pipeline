name: Extract Entities

on:
  workflow_call:
    inputs:
      ingested-date:
        type: string
        default: ''
      model:
        type: string
        default: 'en_core_web_trf'
      batch-size:
        type: number
        default: 32
      word-limit:
        type: number
        default: 300
      overwrite:
        type: boolean
        default: false
      load-s3:
        type: boolean
        default: true
      load-rds:
        type: boolean
        default: true
  workflow_dispatch:
    inputs:
      ingested-date:
        description: 'UTC date to load from RDS (YYYY-MM-DD)'
        type: string
        required: false
        default: ''
      model:
        description: 'spaCy model to use'
        type: string
        default: 'en_core_web_trf'
      batch-size:
        description: 'Batch size for spaCy NER'
        type: number
        default: 32
      word-limit:
        description: 'Entity extraction word limit'
        type: number
        default: 300
      overwrite:
        description: 'Re-extract entities for articles with existing entities'
        type: boolean
        default: false
      load-s3:
        description: 'Load entities to S3'
        type: boolean
        default: true
      load-rds:
        description: 'Load entities to RDS'
        type: boolean
        default: true

jobs:
  extract-entities:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: eu-west-2

      - name: Set up SSH tunnel
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.BASTION_SSH_KEY }}" > ~/.ssh/bastion_key
          chmod 600 ~/.ssh/bastion_key

          ssh-keyscan -H ${{ secrets.BASTION_IP }} >> ~/.ssh/known_hosts 2>&1

          ssh -f -N -L 5432:${{ secrets.RDS_ENDPOINT }}:5432 \
            -o ExitOnForwardFailure=yes \
            -o ConnectTimeout=10 \
            -o ServerAliveInterval=60 \
            -i ~/.ssh/bastion_key \
            ec2-user@${{ secrets.BASTION_IP }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: latest
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-extract-entities-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --with extract_entities

      - name: Cache spaCy assets
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/spacy
          key: spacy-assets-${{ runner.os }}-${{ inputs.model }}

      - name: Check spaCy model
        id: spacy-model
        run: |
          poetry run python - <<'PY'
          import spacy

          model = "${{ inputs.model }}"
          is_installed = spacy.util.is_package(model)
          with open("${GITHUB_OUTPUT}", "a", encoding="utf-8") as handle:
              handle.write(f"installed={str(is_installed).lower()}\n")
          PY

      - name: Install spaCy model
        if: steps.spacy-model.outputs.installed != 'true'
        run: poetry run python -m spacy download ${{ inputs.model }}

      - name: Build command arguments
        id: build-args
        run: |
          if [ -n "${{ inputs.ingested-date }}" ]; then
            ARGS="--ingested-date ${{ inputs.ingested-date }}"
          else
            ARGS="--ingested-date $(date -u +%F)"
          fi
          ARGS="$ARGS --model ${{ inputs.model }}"
          ARGS="$ARGS --batch-size ${{ inputs.batch-size }}"
          if [ "${{ inputs.word-limit }}" -gt 0 ]; then
            ARGS="$ARGS --word-limit ${{ inputs.word-limit }}"
          fi
          if [ "${{ inputs.overwrite }}" = "true" ]; then
            ARGS="$ARGS --overwrite"
          fi
          if [ "${{ inputs.load-s3 }}" = "true" ]; then
            ARGS="$ARGS --load-s3"
          fi
          if [ "${{ inputs.load-rds }}" = "true" ]; then
            ARGS="$ARGS --load-rds"
          fi
          echo "args=$ARGS" >> $GITHUB_OUTPUT

      - name: Run extract_entities
        env:
          PYTHONPATH: src
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          DATABASE_URL: postgresql://postgres:${{ secrets.DB_PASSWORD }}@localhost:5432/contextdb
        run: poetry run python -m extract_entities ${{ steps.build-args.outputs.args }}
